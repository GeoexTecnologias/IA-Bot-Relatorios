{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain-apps/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens: 7535\n"
     ]
    }
   ],
   "source": [
    "db_schema = open('db_schema.txt', 'r')\n",
    "tokens = 0\n",
    "for line in db_schema:\n",
    "    tokens += len(line.split())\n",
    "print(f'Número de tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db_schema.txt') as f:\n",
    "   db_schema = f.read() \n",
    "chunks = splitter.create_documents([db_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain-apps/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "set_llm_cache(SQLiteCache(database_path='./cache/.langchain.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(text):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in text])\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print('Embedding cost in USD:',total_tokens/1000 * 0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 40851\n",
      "Embedding cost in USD: 0.0163404\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletando indice  geoex-sql-embeddings\n"
     ]
    }
   ],
   "source": [
    "pc = pinecone.Pinecone()\n",
    "\n",
    "for i in pc.list_indexes().names():\n",
    "    print('Deletando indice ', i)\n",
    "    pc.delete_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando index geoex-sql-embeddings\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "index_name = 'geoex-sql-embeddings'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print('Criando index',index_name)\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=pinecone.PodSpec(\n",
    "            environment='gcp-starter'\n",
    "        )\n",
    "        \n",
    "    )\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando VectorStore dos metadados do Banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_documents(chunks,embeddings,index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00652,\n",
       " 'namespaces': {'': {'vector_count': 652}},\n",
       " 'total_vector_count': 652}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.Index(index_name).describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ProjetoPEPId'), Document(page_content='PlanejamentoTipoObraId CustoEstimado'), Document(page_content='ProjetoEstudoAmbientalAcaoVegetacaoIdParente'), Document(page_content='ProjetoEstudoAmbientalAcaoTipoId ProjetoEstudoAmbientalAcaoHistoricoId')]\n"
     ]
    }
   ],
   "source": [
    "query = 'Projeto Normal'\n",
    "result = vector_store.similarity_search(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4',temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':50})\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,chain_type='stuff',retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Voce é um assistente chamado GeoAI que so responde em formato de script de\n",
    "    consulta em SQL para SQL server, voce so faz comandos de SELECT e Nunca de Alteração dos dados ou metadados. Baseado nos dados fornecidos, monte a melhor consulta \n",
    "    para responder esta pergunta de forma mais ao pé da letra possível: '{question}'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Pergunta do usuário \n",
    "question = \"Me de um relatorio das medicoes fechadas de forma parcial\"\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template)\n",
    "prompt = prompt_template.format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM MedicaoFechamento WHERE Parcial = 1\n"
     ]
    }
   ],
   "source": [
    "# Output modelo\n",
    "resp = chain.run(prompt)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
