{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco de dados\n"
     ]
    }
   ],
   "source": [
    "import pymssql\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "def connect_db():\n",
    "    server = os.getenv(\"SERVER\")\n",
    "    username = os.getenv(\"USERNAME\")\n",
    "    password = os.getenv(\"PASSWORD\")\n",
    "    database = os.getenv(\"DATABASE\")\n",
    "    port = os.getenv(\"PORT\")\n",
    "    uri = f\"mssql+pymssql://{username}:{password}@{server}/{database}\"\n",
    "    return pymssql.connect(server, username, password, database), uri\n",
    "\n",
    "conn,uri = connect_db()\n",
    "print('Conectado ao banco de dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from sqlalchemy import create_engine\n",
    "# inspector\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "engine=create_engine(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "# Obtenha os nomes das tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabelas = inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # registre em um txt no formato: A tabela <nome da tabela> tem as colunas: <nome da coluna> <nome da coluna> <nome da coluna> ... e pule uma linha\n",
    "# with open('db_schema.txt', 'w') as f:\n",
    "#     for tabela in tabelas:\n",
    "#         f.write(f'table {tabela} cols: ')\n",
    "#         for coluna in inspector.get_columns(tabela):\n",
    "#             f.write(f'{coluna[\"name\"]} ')\n",
    "#         f.write('\\n')\n",
    "#         print(f'Escrevendo {tabela} no arquivo')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens: 5123\n"
     ]
    }
   ],
   "source": [
    "# count tokens\n",
    "tokens = 0\n",
    "db_schema = open('db_schema.txt', 'r')\n",
    "\n",
    "for line in db_schema:\n",
    "    tokens += len(line.split())\n",
    "print(f'Número de tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print lines \n",
    "db_schema = open('db_schema.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Caching the prompt\n",
    "# from langchain.cache import SQLiteCache\n",
    "# from langchain.globals import set_llm_cache\n",
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# question = \"Quantos os projetos tem carteira para setembro de 2021?\"\n",
    "# prompt_template = PromptTemplate.from_template(template=template)\n",
    "# prompt = prompt_template.format(db_schema_list=db_schema_list,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db_schema.txt') as f:\n",
    "   db_schema = f.read() \n",
    "chunks = splitter.create_documents([db_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "set_llm_cache(SQLiteCache(database_path='./cache/.langchain.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(text):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in text])\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print('Embedding cost in USD:',total_tokens/1000 * 0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 18356\n",
      "Embedding cost in USD: 0.007342400000000001\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in pc.list_indexes().names():\n",
    "#     print('Deletando indice ', i)\n",
    "#     pc.delete_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "pc = pinecone.Pinecone()\n",
    "\n",
    "index_name = 'geoex-sql-embeddings'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print('Criando index',index_name)\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=pinecone.PodSpec(\n",
    "            environment='gcp-starter'\n",
    "        )\n",
    "        \n",
    "    )\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando VectorStore dos metadados do Banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_documents(chunks,embeddings,index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00652,\n",
       " 'namespaces': {'': {'vector_count': 652}},\n",
       " 'total_vector_count': 652}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.Index(index_name).describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ProjetoPEPId'), Document(page_content='ProjetoPEPId'), Document(page_content='PlanejamentoTipoObraId CustoEstimado'), Document(page_content='PlanejamentoTipoObraId CustoEstimado')]\n"
     ]
    }
   ],
   "source": [
    "query = 'Projeto Normal'\n",
    "result = vector_store.similarity_search(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':50})\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,chain_type='stuff',retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Voce é um assistente chamado GeoAI que so responde em formato de script de\n",
    "    consulta em SQL para SQL server, voce so faz comandos de SELECT e Nunca de Alteração dos dados ou metadados. Baseado nos dados fornecidos, monte a melhor consulta \n",
    "    para responder esta pergunta de forma mais ao pé da letra possível: '{question}'\n",
    "    \"\"\"\n",
    "    \n",
    "question = \"Quero informacoes sobre o projeto que tem a nota numero 9200848541\"\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template)\n",
    "prompt = prompt_template.format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Voce é um assistente chamado GeoAI que so responde em formato de script de\\n    consulta em SQL para SQL server, voce so faz comandos de SELECT e Nunca de Alteração dos dados ou metadados. Baseado nos dados fornecidos, monte a melhor consulta \\n    para responder esta pergunta de forma mais ao pé da letra possível: 'Quero informacoes sobre o projeto que tem a nota numero 9200848541'\\n    se precisar de mais informacoes ou ficar com dúvida de qual tabela usar, pergunte ao usuário informando as opcoes\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT *\n",
      "FROM ProjetoEletrobrasUC\n",
      "WHERE Numero = 9200848541;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "resp = chain.run(prompt)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
